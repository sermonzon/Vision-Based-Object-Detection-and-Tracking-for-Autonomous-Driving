{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some modules\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_images():\n",
    "    # Function to load calibration images (chessboard images)\n",
    "    route_folder = \"C:/Users/USUARIO/OneDrive - Gasoline Grill/Documentos/DTU/Perception for Autonomous Systems/Final project/34759_final_project_rect/34759_final_project_rect/calib\"\n",
    "    \n",
    "    route_images_left = route_folder + '/image_02/data'\n",
    "    route_images_right = route_folder + '/image_03/data'\n",
    "\n",
    "    images_left = glob.glob(route_images_left+'/*.png')\n",
    "    images_right = glob.glob(route_images_right+'/*.png')\n",
    "    images_left.sort()\n",
    "    images_right.sort()\n",
    "    assert images_left\n",
    "    assert images_right\n",
    "    return images_left, images_right\n",
    "\n",
    "def take_seq_raw_images():\n",
    "    # Function to load raw images (seq 01)\n",
    "    route_folder = \"C:/Users/USUARIO/OneDrive - Gasoline Grill/Documentos/DTU/Perception for Autonomous Systems/Final project/34759_final_project_raw/34759_final_project_raw/seq_01\"\n",
    "    route_images_left = route_folder + '/image_02/data'\n",
    "    route_images_right = route_folder + '/image_03/data'\n",
    "\n",
    "    images_left = glob.glob(route_images_left+'/*.png')\n",
    "    images_right = glob.glob(route_images_right+'/*.png')\n",
    "    images_left.sort()\n",
    "    images_right.sort()\n",
    "    assert images_left\n",
    "    assert images_right\n",
    "    return images_left, images_right\n",
    "\n",
    "def take_seq_rect_images():\n",
    "    # Function to load rect images (seq 01)\n",
    "    route_folder = \"C:/Users/USUARIO/OneDrive - Gasoline Grill/Documentos/DTU/Perception for Autonomous Systems/Final project/34759_final_project_rect/34759_final_project_rect/seq_01\"\n",
    "    route_images_left = route_folder + '/image_02/data'\n",
    "    route_images_right = route_folder + '/image_03/data'\n",
    "\n",
    "    images_left = glob.glob(route_images_left+'/*.png')\n",
    "    images_right = glob.glob(route_images_right+'/*.png')\n",
    "    images_left.sort()\n",
    "    images_right.sort()\n",
    "    assert images_left\n",
    "    assert images_right\n",
    "    return images_left, images_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, time):\n",
    "    # Function to display an image using OpenCV\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.waitKey(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_chessboard_corners(image, size, flags=None, is_gray=True):\n",
    "    # Function to detect chessboard corners in an image\n",
    "    if not is_gray :\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(image, size, flags)\n",
    "    return ret, corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_size(image, scale):\n",
    "    # Function to resize an image by a given scale\n",
    "    w ,h = image.shape[:2]\n",
    "    imagen_duplicated = cv2.resize(image, (h * scale, w * scale), interpolation=cv2.INTER_LINEAR)\n",
    "    return imagen_duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(image, square_size = (400,400), start = (0,0)):\n",
    "    # Function to crop an image into a square of a specific size starting from a given point\n",
    "    h, w = image.shape[:2]\n",
    "    x_start, y_start = start\n",
    "    x_end, y_end = min(x_start + square_size[0], h), min(y_start + square_size[1], w)\n",
    "    new_image = image[x_start:x_end, y_start:y_end]\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_position_and_start():\n",
    "    # Function to provide the positions and sizes for image regions to search for chessboards\n",
    "    starts_l = [(0,0),(80,300),(60,380), (245,470),(385,390),(280,680),(80,790),(280,800),(50,1010),(220,1070),(370,950),(100,1210),(100,1310)]\n",
    "    starts_r = [(0,0),(130,250),(80,340), (210,400),(380,380),(250,560),(0,620),(250,690),(0,850),(180,940),(350,860),(100,1120),(100,1190)]\n",
    "\n",
    "    size_l = [(400,350),(250,200),(100,300),(150,200),(120,300),(500,100),(200,150),(500,100),(200,250),(170,170),(250,250),(380,110),(400,105)]\n",
    "    size_r = [(400,300),(200,200),(100,200),(180,180),(130,200),(200,170),(300,300),(200,160),(250,300),(200,200),(200,200),(400,90),(400,100)]\n",
    "    \n",
    "    return starts_l,size_l, starts_r, size_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_squares():\n",
    "    # Function to return a predefined list of chessboard square numbers\n",
    "    squares = [(7,11),(7,11),(5,7),(7,5),(5,7),(7,5),(5,7),(7,5),(5,7),(7,5),(5,7),(15,5),(7,5)]\n",
    "    return squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_multiple_chessboards(image, which, is_gray=False, flags = None, scale=3, show_images=False):\n",
    "    # Function to detect multiple chessboards in a single image, for both left or right camera\n",
    "    if not is_gray:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    start_l, size_l, start_r, size_r = take_position_and_start()\n",
    "    squares = take_squares()\n",
    "    founds = []\n",
    "    detected_corners = []\n",
    "    found = False\n",
    "\n",
    "    for i, (stl, str, szl, szr) in enumerate(zip(start_l, start_r, size_l, size_r)):\n",
    "        new_image = image.copy()\n",
    "        if which == 'l':\n",
    "            st,sz = stl, szl\n",
    "        else:   \n",
    "            st,sz = str,szr\n",
    "        sq = squares[i]\n",
    "        \n",
    "        new_image = transform_image(new_image, square_size=sz, start=st)\n",
    "        new_image = change_size(new_image,scale)        \n",
    "        ret, corners = detect_chessboard_corners(new_image, sq, flags=flags)\n",
    "        \n",
    "        if show_images:\n",
    "            show_image(new_image,0)\n",
    "\n",
    "        if ret:\n",
    "            incremento = np.array([st[1],st[0]]).reshape(1, 1, 2)\n",
    "            div_scale = np.array([scale]).reshape(1,1,1)\n",
    "            corners2 = (corners/div_scale) + incremento\n",
    "            corners2 = corners2.astype(corners.dtype)\n",
    "            corners = corners2.copy()\n",
    "\n",
    "            if corners[0,0,0] > corners[-1,0,0]:\n",
    "                corners = np.flip(corners, axis=0)\n",
    "            corners = np.array(corners, dtype=np.float32)\n",
    "\n",
    "            detected_corners.append(corners)\n",
    "            founds.append(True)\n",
    "            found = True\n",
    "        else:\n",
    "            founds.append(False)\n",
    "            detected_corners.append([])\n",
    "\n",
    "    return found, detected_corners, founds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera_for_intrinsic_parameters(images, which, show_images=False, check_images=[]):\n",
    "    # Function to calibrate the camera by detecting chessboards and estimating intrinsic parameters\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TermCriteria_COUNT + cv2.TERM_CRITERIA_COUNT, 40, 0.001)\n",
    "    number_of_chessboards = 13\n",
    "    squares = take_squares()\n",
    "    world_scaling = 10\n",
    "    flags =  cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK\n",
    "    conv_size = (3,3)\n",
    "\n",
    "\n",
    "    objpoints_dict = {}\n",
    "    for row,col in squares:\n",
    "        objp = np.zeros((row*col,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:row,0:col].T.reshape(-1,2)\n",
    "        objpoints_dict[(row,col)] = world_scaling * objp\n",
    "\n",
    "    img = cv2.imread(images[0])\n",
    "    height,width = img.shape[:2]\n",
    "        \n",
    "    imgpoints = [] \n",
    "    objpoints = [] \n",
    "\n",
    "\n",
    "    for i, frame in enumerate(images):\n",
    "        if check_images is not None and frame[len(frame)-6:] not in check_images:\n",
    "            continue\n",
    "\n",
    "        frame = cv2.imread(frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ret,corners,founds = detect_multiple_chessboards(gray, which = which, is_gray=True, flags=flags)\n",
    "\n",
    "        if ret:\n",
    "            for i in range(number_of_chessboards):\n",
    "                if founds[i]:\n",
    "                    corners[i] = cv2.cornerSubPix(gray, corners[i], conv_size, (-1, -1), criteria)\n",
    "                    objpoints.append(objpoints_dict[squares[i]])\n",
    "                    imgpoints.append(corners[i])\n",
    "                    cv2.drawChessboardCorners(frame, squares[i], corners[i], ret)\n",
    "\n",
    "            if show_images:\n",
    "                show_image(frame,0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    ret, cmtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (width, height), None, None)\n",
    "    print('chessboards detected',sum(founds))\n",
    "    print('rmse of camera calibration:', ret)\n",
    "    \n",
    "    return cmtx, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_calibration(images_left, images_right, cmtx_l, dist_l, cmtx_r, dist_r, show_images=False, check_images=[]):\n",
    "    # Function to perform stereo calibration using chessboard images\n",
    "    squares = take_squares()\n",
    "    world_scaling = 10\n",
    "    number_of_chessboards = 13\n",
    "    flags =  cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.0001)\n",
    "    conv_size = (3,3)\n",
    "    img = cv2.imread(images_left[0])\n",
    "    height,width = img.shape[:2]\n",
    "\n",
    "    objpoints = []\n",
    "    imgpoints_left = []\n",
    "    imgpoints_right = []\n",
    "\n",
    "    objpoints_dict = {}\n",
    "    for size in squares:\n",
    "        objp = np.zeros((size[0]*size[1],3), np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:size[0], 0:size[1]].T.reshape(-1, 2)\n",
    "        objpoints_dict[size] = objp * world_scaling\n",
    "\n",
    "\n",
    "    for fname_left, fname_right in zip(images_left, images_right):\n",
    "        if check_images is not None and fname_left[len(fname_left)-6:] not in check_images:\n",
    "            continue\n",
    "\n",
    "        img_left = cv2.imread(fname_left)\n",
    "        img_right = cv2.imread(fname_right)\n",
    "\n",
    "        gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
    "        gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img_left_draw = img_left.copy()\n",
    "        img_right_draw = img_right.copy()\n",
    "\n",
    "        ret_l,corners_l,founds_l = detect_multiple_chessboards(gray_left, which = 'l', is_gray=True, flags=flags)\n",
    "        ret_r,corners_r,founds_r = detect_multiple_chessboards(gray_right, which = 'r', is_gray=True, flags=flags)\n",
    "        print('chessboards found', sum(founds_l), sum(founds_r))\n",
    "\n",
    "        if ret_l and ret_r:\n",
    "\n",
    "            for i in range(number_of_chessboards):\n",
    "                if founds_l[i] and founds_r[i]:\n",
    "                    corners_l[i] = cv2.cornerSubPix(gray_left, corners_l[i], conv_size, (-1, -1), criteria)\n",
    "                    corners_r[i] = cv2.cornerSubPix(gray_right, corners_r[i], conv_size, (-1, -1), criteria)\n",
    "\n",
    "                    cl,cr = corners_l[i],corners_r[i] \n",
    "                    rows,columns = squares[i]\n",
    "                    objpoints.append(objpoints_dict[squares[i]])\n",
    "                    imgpoints_left.append(cl)\n",
    "                    imgpoints_right.append(cr)\n",
    "\n",
    "                    cv2.drawChessboardCorners(img_left_draw, (rows,columns), cl, founds_l[i])\n",
    "                    cv2.drawChessboardCorners(img_right_draw, (rows,columns), cr, founds_r[i])\n",
    "\n",
    "            if show_images:\n",
    "                show_image(img_left_draw,0)\n",
    "                show_image(img_right_draw,0)\n",
    "\n",
    "        img_left_draw = img_left.copy()\n",
    "        img_right_draw = img_right.copy()\n",
    "    \n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    stereocalibration_flags = 0\n",
    "    ret, CM1, dist0, CM2, dist1, R, T, E, F = cv2.stereoCalibrate(\n",
    "            objectPoints=objpoints, \n",
    "            imagePoints1=imgpoints_left, \n",
    "            imagePoints2=imgpoints_right, \n",
    "            cameraMatrix1=cmtx_l, \n",
    "            distCoeffs1=dist_l,\n",
    "            cameraMatrix2=cmtx_r, \n",
    "            distCoeffs2=dist_r, \n",
    "            imageSize=(width,height), \n",
    "            criteria = criteria, \n",
    "            flags = stereocalibration_flags)\n",
    "\n",
    "    print('rmse of stereo calibration: ', ret)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return ret, CM1, dist0, CM2, dist1, R, T, E, F, objpoints,imgpoints_left, imgpoints_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matching_with_ransac(image1, image2):\n",
    "    # Function to perform feature matching between two images using ORB and RANSAC\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(image1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(image2, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    \n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    _, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    inliers = mask.sum()\n",
    "    \n",
    "    return inliers, len(matches)\n",
    "\n",
    "def fourier_similarity(image1, image2):\n",
    "    # Function to compute Fourier Transform similarity between two images\n",
    "    f1 = np.fft.fft2(cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY))\n",
    "    f2 = np.fft.fft2(cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    f1 = np.fft.fftshift(f1)\n",
    "    f2 = np.fft.fftshift(f2)\n",
    "    \n",
    "    mag1 = np.abs(f1)\n",
    "    mag2 = np.abs(f2)\n",
    "    \n",
    "    similarity = np.sum((mag1 - np.mean(mag1)) * (mag2 - np.mean(mag2)))\n",
    "    similarity /= np.sqrt(np.sum((mag1 - np.mean(mag1)) ** 2) * np.sum((mag2 - np.mean(mag2)) ** 2))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_rectification(cmtx_l, dist_l, cmtx_r,dist_r, R_l,R_r,T_l,T_r, compute_similarities = True, show_images=False, undistort=False, check_images = None):\n",
    "    # Function to perform stereo rectification and optionally compute image similarities\n",
    "    images_raw_left, images_raw_right = take_seq_raw_images()\n",
    "    images_rect_left, images_rect_right = take_seq_rect_images()\n",
    "    \n",
    "    R_l = np.asarray(R_l, dtype=np.float64)\n",
    "    R_r = np.asarray(R_r, dtype=np.float64)\n",
    "    T_l = np.asarray(T_l, dtype=np.float64)\n",
    "    T_r = np.asarray(T_r, dtype=np.float64)\n",
    "    cmtx_l = np.asarray(cmtx_l, dtype=np.float64)\n",
    "    cmtx_r = np.asarray(cmtx_r, dtype=np.float64)\n",
    "    dist_l = np.asarray(dist_l, dtype=np.float64)\n",
    "    dist_r = np.asarray(dist_r, dtype=np.float64)\n",
    "\n",
    "    \n",
    "    h, w = cv2.imread(images_raw_left[0]).shape[:2]\n",
    "    image_size = (w, h)\n",
    "\n",
    "    \n",
    "    R_l, R_r, P_l, P_r, Q, roi_l,roi_r = cv2.stereoRectify(cmtx_l, dist_l, cmtx_r, dist_r, image_size, R_r, T_r, alpha=0.4)\n",
    "\n",
    "        \n",
    "    map1_left, map2_left = cv2.initUndistortRectifyMap(\n",
    "        cmtx_l, dist_l, R_l, P_l, image_size, cv2.CV_32FC1\n",
    "    )\n",
    "\n",
    "    map1_right, map2_right = cv2.initUndistortRectifyMap(\n",
    "        cmtx_r, dist_r, R_r, P_r, image_size, cv2.CV_32FC1\n",
    "    )\n",
    "\n",
    "    four_sim_l = []\n",
    "    feature_sim_l = []\n",
    "    four_sim_r = []\n",
    "    feature_sim_r = []\n",
    "\n",
    "    output_folder_left = \"rectified_left\"\n",
    "    output_folder_right = \"rectified_right\"\n",
    "    os.makedirs(output_folder_left, exist_ok=True)\n",
    "    os.makedirs(output_folder_right, exist_ok=True)\n",
    "\n",
    "    for fraw_left, fraw_right, frect_left, frect_right in zip(images_raw_left, images_raw_right, images_rect_left, images_rect_right):\n",
    "        if check_images is not None and fraw_left[len(fraw_left)-7:] not in check_images:\n",
    "            continue\n",
    "\n",
    "        left_raw_image = cv2.imread(fraw_left)\n",
    "        right_raw_image = cv2.imread(fraw_right)\n",
    "        left_rect_image = cv2.imread(frect_left)\n",
    "        right_rect_image = cv2.imread(frect_right)\n",
    "\n",
    "        rectified_left = left_raw_image.copy()\n",
    "        rectified_right = right_raw_image.copy()\n",
    "\n",
    "        h_l,w_l = left_raw_image.shape[:2]\n",
    "        h_r,w_r = right_raw_image.shape[:2]\n",
    "\n",
    "\n",
    "        rectified_left = cv2.remap(rectified_left, map1_left, map2_left, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "        rectified_right = cv2.remap(rectified_right, map1_right, map2_right, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "        x_l,y_l,w_l,h_l = roi_l\n",
    "        x_r,y_r,w_r,h_r = roi_r\n",
    "\n",
    "        rectified_left = rectified_left[y_l:y_l+h_l, x_l:x_l+w_l]\n",
    "        rectified_right = rectified_right[y_r:y_r+h_r, x_r:x_r+w_r]\n",
    "\n",
    "        # Save rectified images\n",
    "        left_filename = os.path.join(output_folder_left, os.path.basename(fraw_left))\n",
    "        right_filename = os.path.join(output_folder_right, os.path.basename(fraw_right))\n",
    "\n",
    "        cv2.imwrite(left_filename, rectified_left)\n",
    "        cv2.imwrite(right_filename, rectified_right)\n",
    "\n",
    "        width = w_l\n",
    "        height = h_l\n",
    "        rectified_left = cv2.resize(rectified_left, (width, height))\n",
    "        left_rect_image = cv2.resize(left_rect_image, (width, height))\n",
    "        rectified_right = cv2.resize(rectified_right, (width, height))\n",
    "        right_rect_image = cv2.resize(right_rect_image, (width, height))\n",
    "\n",
    "\n",
    "        if show_images:\n",
    "            right_raw_image = cv2.resize(right_raw_image, (width,height))\n",
    "            cv2.putText(right_raw_image, \"Raw Image\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.putText(rectified_right, \"Rectified Image (by us)\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.putText(right_rect_image, \"Rectified Image (given from assignment)\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            combined_image = np.vstack((right_raw_image, rectified_right,right_rect_image))\n",
    "            windowname_1 = \"Rectified\"\n",
    "            cv2.namedWindow(windowname_1, cv2.WINDOW_NORMAL) \n",
    "            cv2.imshow(windowname_1, combined_image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        if compute_similarities:\n",
    "            similarity_l = fourier_similarity(left_rect_image, rectified_left)\n",
    "            similarity_r = fourier_similarity(right_rect_image, rectified_right)\n",
    "            four_sim_l.append(similarity_l)\n",
    "            four_sim_r.append(similarity_r)\n",
    "\n",
    "            inliers_l, total_matches_l = feature_matching_with_ransac(left_rect_image, rectified_left)\n",
    "            inliers_r, total_matches_r = feature_matching_with_ransac(right_rect_image, rectified_right)\n",
    "            similarity_l = inliers_l / total_matches_l\n",
    "            similarity_r = inliers_r / total_matches_r\n",
    "            feature_sim_l.append(similarity_l)\n",
    "            feature_sim_r.append(similarity_r)\n",
    "    if compute_similarities:\n",
    "        print('feature_l', sum(feature_sim_l)/len(feature_sim_l))\n",
    "        print('feature_r', sum(feature_sim_r)/len(feature_sim_r))\n",
    "        print('four_l', sum(four_sim_l)/len(four_sim_l))\n",
    "        print('four_r', sum(four_sim_r)/len(four_sim_r))\n",
    "\n",
    "    print('saved rectified left images to', output_folder_left)\n",
    "    print('saved rectified right images to', output_folder_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting camera calibration for left camera\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chessboards detected 12\n",
      "rmse of camera calibration: 0.22227990020175312\n",
      "Starting camera calibration for right camera\n",
      "chessboards detected 11\n",
      "rmse of camera calibration: 0.1833643034120145\n",
      "Starting stereo calibration\n",
      "chessboards found 12 10\n",
      "chessboards found 11 10\n",
      "chessboards found 12 11\n",
      "rmse of stereo calibration:  0.18616252363650612\n",
      "Starting stereo rectification\n",
      "saved rectified left images to rectified_left\n",
      "saved rectified right images to rectified_right\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    check_images = ['00.png','01.png','02.png']  # select check_images = None for selecting all of the images. If not, select check_images = ['00.png','01.png','02.png', ...]\n",
    "    images_left, images_right = take_images()\n",
    "    print('Starting camera calibration for left camera')\n",
    "    cmtx_l, dist_l = calibrate_camera_for_intrinsic_parameters(images_left, which='l', check_images=check_images, show_images=False)\n",
    "    print('Starting camera calibration for right camera')\n",
    "    cmtx_r, dist_r = calibrate_camera_for_intrinsic_parameters(images_right, which = 'r', check_images=check_images, show_images=False)\n",
    "    print('Starting stereo calibration')\n",
    "    ret, CM1, dist0, CM2, dist1, R, T, E, F, objpoints,imgpoints_left, imgpoints_right = stereo_calibration(images_left, images_right, cmtx_l, dist_l, cmtx_r, dist_r, check_images=check_images, show_images=False)\n",
    "    R_l = np.eye(3, dtype=np.float32)\n",
    "    T_l = np.array([0., 0., 0.]).reshape((3, 1))\n",
    "    R_r = R\n",
    "    T_r = T\n",
    "    print('Starting stereo rectification')\n",
    "    check_images = None #['000.png', '001.png']   # select check_images = None for selecting all of the images. If not, select check_images = ['000.png','001.png','002.png', ...]\n",
    "    stereo_rectification(cmtx_l,dist_l,cmtx_r,dist_r,R_l,R_r,T_l,T_r, compute_similarities=False, show_images=False, undistort=True, check_images = check_images) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
